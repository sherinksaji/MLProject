{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the approach by using an n-th order HMM, whereby the HMM can depend on not only the current state but also the previous n-states. In this case, we have adopted n=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extracting data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.read().strip().split('\\n\\n')\n",
    "    return [sentence.split('\\n') for sentence in data]\n",
    "\n",
    "# Adjusting the paths for ES and RU datasets\n",
    "train_data = load_data('Data/ES/train')\n",
    "dev_in_data = load_data('Data/ES/dev.in')\n",
    "with open('Data/ES/dev.out', 'r', encoding='utf-8') as f:\n",
    "    dev_tags_actual = [sentence.split() for sentence in f.read().strip().split('\\n\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set to RU/ES\n",
    "lang = 'ES'\n",
    "#set to test/dev\n",
    "flag = 'test'\n",
    "\n",
    "\n",
    "if(flag=='test'):\n",
    "    dev_in_data = load_data(f'Test/{lang}/{flag}.in')\n",
    "    dev_out_data = f'Test/{lang}/{flag}.p4.out'\n",
    "    \n",
    "\n",
    "elif(flag=='dev'):\n",
    "    dev_in_data = load_data(f'Data/{lang}/{flag}.in')\n",
    "    dev_out_data = f'Data/{lang}/{flag}.p4.out'\n",
    "    with open(f'Data/{lang}/dev.out', 'r', encoding='utf-8') as f:\n",
    "        dev_tags_actual = [sentence.split() for sentence in f.read().strip().split('\\n\\n')]\n",
    "\n",
    "# Adjusting the paths for ES and RU datasets\n",
    "train_data = load_data(f'Data/{lang}/train')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {}\n",
    "observations = {}\n",
    "\n",
    "for sentence in train_data:\n",
    "    for line in sentence:\n",
    "        word, tag = line.strip().split(maxsplit=1)\n",
    "        states[tag] = states.get(tag, 0) + 1\n",
    "        if tag not in observations:\n",
    "            observations[tag] = {}\n",
    "        observations[tag][word] = observations[tag].get(word, 0) + 1\n",
    "\n",
    "state_list = list(states.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_probabilities(data, state_list):\n",
    "    # Initialize counts\n",
    "    start_count = defaultdict(int)\n",
    "    transition_count = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "    emission_count = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Populate counts\n",
    "    for sentence in data:\n",
    "        if len(sentence) < 3:  # Skip sentences that are too short\n",
    "            continue\n",
    "\n",
    "        # Splitting and extracting the word and state for first two words/states\n",
    "        word1, state1 = sentence[0].strip().split()\n",
    "        word2, state2 = sentence[1].strip().split()\n",
    "        start_count[state1] += 1\n",
    "        emission_count[state1][word1] += 1\n",
    "        emission_count[state2][word2] += 1\n",
    "\n",
    "        # Rest of the sentence\n",
    "        for i in range(2, len(sentence)):\n",
    "            word3, state3 = sentence[i].strip().split(maxsplit=1)\n",
    "            transition_count[state1][state2][state3] += 1\n",
    "            emission_count[state3][word3] += 1\n",
    "            state1, state2 = state2, state3\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    # Start transition probabilities\n",
    "    start_transition_prob = {state: count / sum(start_count.values()) for state, count in start_count.items()}\n",
    "\n",
    "    # Transition probabilities\n",
    "    transition_prob = {}\n",
    "    for s1, s1_dict in transition_count.items():\n",
    "        transition_prob[s1] = {}\n",
    "        for s2, s2_dict in s1_dict.items():\n",
    "            transition_prob[s1][s2] = {}\n",
    "            for s3, count in s2_dict.items():\n",
    "                total = sum(s2_dict.values())\n",
    "                transition_prob[s1][s2][s3] = count / total if total != 0 else 0.0\n",
    "\n",
    "    # Emission probabilities\n",
    "    emission_prob = {}\n",
    "    for state, word_count in emission_count.items():\n",
    "        emission_prob[state] = {}\n",
    "        total = sum(word_count.values())\n",
    "        for word, count in word_count.items():\n",
    "            emission_prob[state][word] = count / total\n",
    "\n",
    "    return start_transition_prob, transition_prob, emission_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = list(states.keys())\n",
    "start_transition_prob, transition_prob, emission_prob = compute_probabilities(train_data, state_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': {'O': {'O': 0.955137542136585,\n",
       "   'B-positive': 0.030796121353364684,\n",
       "   'B-negative': 0.012235215780931374,\n",
       "   'B-neutral': 0.0018311207291189812},\n",
       "  'B-positive': {'O': 0.8742857142857143,\n",
       "   'I-positive': 0.12285714285714286,\n",
       "   'B-neutral': 0.0009523809523809524,\n",
       "   'B-positive': 0.0019047619047619048},\n",
       "  'B-negative': {'O': 0.8290598290598291, 'I-negative': 0.17094017094017094},\n",
       "  'B-neutral': {'I-neutral': 0.24193548387096775, 'O': 0.7580645161290323}},\n",
       " 'B-positive': {'O': {'O': 0.9393282773564464,\n",
       "   'B-neutral': 0.0032502708559046588,\n",
       "   'B-positive': 0.0552546045503792,\n",
       "   'B-negative': 0.0021668472372697724},\n",
       "  'I-positive': {'I-positive': 0.6814814814814815, 'O': 0.31851851851851853},\n",
       "  'B-neutral': {'O': 1.0},\n",
       "  'B-positive': {'O': 1.0}},\n",
       " 'B-negative': {'O': {'O': 0.9858156028368794,\n",
       "   'B-negative': 0.014184397163120567},\n",
       "  'I-negative': {'O': 0.3382352941176471, 'I-negative': 0.6617647058823529}},\n",
       " 'B-neutral': {'I-neutral': {'I-neutral': 0.4666666666666667,\n",
       "   'O': 0.5333333333333333},\n",
       "  'O': {'O': 1.0}},\n",
       " 'I-neutral': {'I-neutral': {'I-neutral': 0.75, 'O': 0.25}, 'O': {'O': 1.0}},\n",
       " 'I-positive': {'I-positive': {'I-positive': 0.4887640449438202,\n",
       "   'O': 0.5112359550561798},\n",
       "  'O': {'O': 0.9385964912280702, 'B-positive': 0.06140350877192982}},\n",
       " 'I-negative': {'O': {'O': 0.9838709677419355,\n",
       "   'B-positive': 0.016129032258064516},\n",
       "  'I-negative': {'O': 0.4368932038834951, 'I-negative': 0.5631067961165048}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    # Initialize the Viterbi matrix. \n",
    "    V = [{}]\n",
    "\n",
    "    # Initialize the first column of the matrix with the start probabilities\n",
    "    for st in states:\n",
    "        V[0][st] = {\"prob\": start_p.get(st, 0) * emit_p[st].get(obs[0], 0), \"prev\": None}\n",
    "\n",
    "    # Main loop through the observations updating the Viterbi matrix\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        for st in states:\n",
    "            # For each state, find the maximum transition probability \n",
    "            # considering all possible previous state combinations.\n",
    "            max_trans_prob, prev_st1_max, prev_st2_max = max(\n",
    "                (V[t-1][prev_st1][\"prob\"] * trans_p[prev_st1].get(prev_st2, {}).get(st, 0), prev_st1, prev_st2)\n",
    "                for prev_st1 in states for prev_st2 in states\n",
    "            )\n",
    "\n",
    "            # Multiply the max transition probability with emission probability\n",
    "            max_prob = max_trans_prob * emit_p[st].get(obs[t], 0)\n",
    "\n",
    "            # Store the maximum probability and previous state information\n",
    "            V[t][st] = {\"prob\": max_prob, \"prev\": (prev_st1_max, prev_st2_max)}\n",
    "\n",
    "    # Now, backtrack to find the most probable sequence of states\n",
    "    opt = []\n",
    "\n",
    "    # Find the state with the maximum probability for the last observation\n",
    "    max_prob = max(value[\"prob\"] for value in V[-1].values())\n",
    "    previous = None\n",
    "\n",
    "    for st, data in V[-1].items():\n",
    "        if data[\"prob\"] == max_prob:\n",
    "            opt.append(st)\n",
    "            previous = st\n",
    "            break\n",
    "\n",
    "    # Backtrack through the Viterbi matrix to find the sequence of states\n",
    "    for t in range(len(V) - 2, -1, -1):\n",
    "        opt.insert(0, V[t + 1][previous][\"prev\"][1])\n",
    "        previous = V[t + 1][previous][\"prev\"][1]\n",
    "\n",
    "    # Return the most probable sequence of states\n",
    "    return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags_viterbi = [viterbi([word.split()[0] for word in sentence], state_list, start_transition_prob, transition_prob, emission_prob) for sentence in dev_in_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_from_tags(tags):\n",
    "    entities = []\n",
    "    entity = []\n",
    "    for tag in tags:\n",
    "        if tag.startswith(\"B-\"):\n",
    "            if entity:\n",
    "                entities.append(tuple(entity))\n",
    "                entity = []\n",
    "            entity.append(tag)\n",
    "        elif tag.startswith(\"I-\"):\n",
    "            entity.append(tag)\n",
    "        else:\n",
    "            if entity:\n",
    "                entities.append(tuple(entity))\n",
    "                entity = []\n",
    "    if entity:\n",
    "        entities.append(tuple(entity))\n",
    "    return set(entities)\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "\n",
    "if(flag=='dev'):\n",
    "    for pred, actual in zip(predicted_tags_viterbi, dev_tags_actual):\n",
    "        predicted_entities = extract_entities_from_tags(pred)\n",
    "        actual_entities = extract_entities_from_tags(actual)\n",
    "        TP += len(predicted_entities.intersection(actual_entities))\n",
    "        FP += len(predicted_entities - actual_entities)\n",
    "        FN += len(actual_entities - predicted_entities)\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = 1.0  # or 0.0, depending on how you want to define it in this case\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "\n",
    "    if TP + FN == 0:\n",
    "        recall = 1.0  # or 0.0\n",
    "    else:\n",
    "        recall = TP / (TP + FN)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F-score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicted = []\n",
    "\n",
    "# Open the output file for writing using UTF-8 encoding\n",
    "with open(dev_out_data, 'w', encoding='utf-8') as file:\n",
    "    for s in range(len(dev_in_data)):\n",
    "        for wi in range(len(dev_in_data[s])):\n",
    "            line = dev_in_data[s][wi]+\" \"+predicted_tags_viterbi[s][wi]\n",
    "            if line != \"\\n\":\n",
    "                file.write(line + '\\n')\n",
    "            else:\n",
    "                file.write(line)\n",
    "        file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
