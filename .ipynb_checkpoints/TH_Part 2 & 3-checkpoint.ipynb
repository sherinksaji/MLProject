{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Working for both ES and RU\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def load_dev_in_data(file_path):\n",
    "    \"\"\"Specific function to load dev.in data, which only contains words.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.read().strip().split('\\n\\n')\n",
    "    return [[word for word in sentence.split('\\n') if word.strip()] for sentence in data]\n",
    "\n",
    "def load_data_modified_v7(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.read().strip().split('\\n\\n')\n",
    "    # Filter out empty lines within sentences and handle lines with extra spaces\n",
    "    processed_data = []\n",
    "    for sentence in data:\n",
    "        processed_sentence = []\n",
    "        for line in sentence.split('\\n'):\n",
    "            if line.strip():  # Check if line is not empty\n",
    "                match = re.search(r'^(.*)\\s(\\S+)$', line)\n",
    "                if match:\n",
    "                    word, tag = match.groups()\n",
    "                    processed_sentence.append(f\"{word} {tag}\")\n",
    "        # Add the processed sentence to the data only if it's not empty\n",
    "        if processed_sentence:\n",
    "            processed_data.append(processed_sentence)\n",
    "    return processed_data\n",
    "\n",
    "def compute_probabilities_v2(data, state_list):\n",
    "    start_transition_count = {state: 0 for state in state_list}\n",
    "    transition_count = {state: {state2: 0 for state2 in state_list} for state in state_list}\n",
    "    emission_count = {state: {} for state in state_list}\n",
    "    state_count = {state: 0 for state in state_list}\n",
    "\n",
    "    for sentence in data:\n",
    "        prev_state = None\n",
    "        for line in sentence:\n",
    "            match = re.search(r'^(.*)\\s(\\S+)$', line.strip())\n",
    "            if match:\n",
    "                word, state = match.groups()\n",
    "                if prev_state is None:\n",
    "                    start_transition_count[state] += 1\n",
    "                else:\n",
    "                    transition_count[prev_state][state] += 1\n",
    "                    emission_count[prev_state][word] = emission_count[prev_state].get(word, 0) + 1\n",
    "                state_count[state] += 1\n",
    "                prev_state = state\n",
    "        if prev_state:\n",
    "            emission_count[prev_state][word] = emission_count[prev_state].get(word, 0) + 1\n",
    "\n",
    "    total_sentences = len(data)\n",
    "    start_transition_prob = {state: count / total_sentences for state, count in start_transition_count.items()}\n",
    "    transition_prob = {state: {state2: count2 / state_count[state] for state2, count2 in count.items()} for state, count in transition_count.items()}\n",
    "    emission_prob = {state: {word: count / state_count[state] for word, count in state_emission_count.items()} for state, state_emission_count in emission_count.items()}\n",
    "\n",
    "    return start_transition_prob, transition_prob, emission_prob\n",
    "\n",
    "def extract_entities_from_tags(tags):\n",
    "    entities = []\n",
    "    entity = []\n",
    "    for tag in tags:\n",
    "        if tag.startswith(\"B-\"):\n",
    "            if entity:\n",
    "                entities.append(tuple(entity))\n",
    "                entity = []\n",
    "            entity.append(tag)\n",
    "        elif tag.startswith(\"I-\"):\n",
    "            entity.append(tag)\n",
    "        else:\n",
    "            if entity:\n",
    "                entities.append(tuple(entity))\n",
    "                entity = []\n",
    "    if entity:\n",
    "        entities.append(tuple(entity))\n",
    "    return set(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x</th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#UNK#</th>\n",
       "      <th>%</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>.</th>\n",
       "      <th>..</th>\n",
       "      <th>...</th>\n",
       "      <th>Éramos</th>\n",
       "      <th>éramos</th>\n",
       "      <th>último</th>\n",
       "      <th>única</th>\n",
       "      <th>único</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>…</th>\n",
       "      <th>€</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-negative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-positive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-negative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-positive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.057308</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.055896</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "x                  !         \"     #UNK#         %         (         )  \\\n",
       "y                                                                        \n",
       "B-negative  0.000000  0.000000  0.005051  0.000000  0.000000  0.000000   \n",
       "B-neutral   0.000000  0.000000  0.021739  0.000000  0.000000  0.000000   \n",
       "B-positive  0.000000  0.000000  0.003497  0.000000  0.000000  0.000000   \n",
       "I-negative  0.000000  0.011628  0.008772  0.000000  0.000000  0.000000   \n",
       "I-neutral   0.000000  0.000000  0.028571  0.000000  0.000000  0.000000   \n",
       "I-positive  0.000000  0.006349  0.005848  0.000000  0.000000  0.000000   \n",
       "O           0.005442  0.001343  0.000211  0.000413  0.004512  0.004512   \n",
       "\n",
       "x                  ,         -         .        ..  ...    Éramos    éramos  \\\n",
       "y                                                   ...                       \n",
       "B-negative  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "B-neutral   0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "B-positive  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "I-negative  0.017442  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "I-neutral   0.000000  0.022727  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "I-positive  0.006349  0.003175  0.003175  0.000000  ...  0.000000  0.000000   \n",
       "O           0.057308  0.000964  0.055896  0.000654  ...  0.000069  0.000034   \n",
       "\n",
       "x             último     única    único         ’         “         ”  \\\n",
       "y                                                                       \n",
       "B-negative  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "B-neutral   0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "B-positive  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "I-negative  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "I-neutral   0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "I-positive  0.000000  0.000000  0.00000  0.000000  0.003175  0.003175   \n",
       "O           0.000276  0.000241  0.00031  0.000276  0.000999  0.001171   \n",
       "\n",
       "x                  …         €  \n",
       "y                               \n",
       "B-negative  0.002618  0.000000  \n",
       "B-neutral   0.000000  0.000000  \n",
       "B-positive  0.000000  0.000000  \n",
       "I-negative  0.000000  0.000000  \n",
       "I-neutral   0.000000  0.000000  \n",
       "I-positive  0.000000  0.003175  \n",
       "O           0.001550  0.000895  \n",
       "\n",
       "[7 rows x 950 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x</th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#UNK#</th>\n",
       "      <th>%</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>.</th>\n",
       "      <th>..</th>\n",
       "      <th>...</th>\n",
       "      <th>эту</th>\n",
       "      <th>юбилей</th>\n",
       "      <th>юбилея</th>\n",
       "      <th>я</th>\n",
       "      <th>явно</th>\n",
       "      <th>язык</th>\n",
       "      <th>яйцом</th>\n",
       "      <th>января</th>\n",
       "      <th>–</th>\n",
       "      <th>…</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-negative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-positive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-negative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-positive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045151</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.021911</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.058973</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 1598 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "x                  !         \"     #UNK#         %         (         )  \\\n",
       "y                                                                        \n",
       "B-negative  0.000000  0.000000  0.003876  0.000000  0.000000  0.000000   \n",
       "B-neutral   0.000000  0.009615  0.008197  0.000000  0.000000  0.000000   \n",
       "B-positive  0.000000  0.002691  0.001486  0.000000  0.000000  0.000000   \n",
       "I-negative  0.000000  0.014085  0.009091  0.000000  0.000000  0.000000   \n",
       "I-neutral   0.000000  0.057971  0.020408  0.000000  0.000000  0.000000   \n",
       "I-positive  0.000000  0.045151  0.003165  0.000000  0.000000  0.000000   \n",
       "O           0.021911  0.004590  0.000139  0.000296  0.006687  0.013596   \n",
       "\n",
       "x                  ,         -         .        ..  ...       эту    юбилей  \\\n",
       "y                                                   ...                       \n",
       "B-negative  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "B-neutral   0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "B-positive  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "I-negative  0.014085  0.000000  0.007042  0.000000  ...  0.000000  0.000000   \n",
       "I-neutral   0.057971  0.014493  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "I-positive  0.008361  0.001672  0.001672  0.000000  ...  0.000000  0.000000   \n",
       "O           0.091791  0.008710  0.058973  0.001505  ...  0.000148  0.000099   \n",
       "\n",
       "x             юбилея         я      явно      язык     яйцом    января  \\\n",
       "y                                                                        \n",
       "B-negative  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "B-neutral   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "B-positive  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "I-negative  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "I-neutral   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "I-positive  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "O           0.000025  0.004022  0.000345  0.000025  0.000025  0.000074   \n",
       "\n",
       "x                  –         …  \n",
       "y                               \n",
       "B-negative  0.000000  0.000000  \n",
       "B-neutral   0.000000  0.000000  \n",
       "B-positive  0.000000  0.000000  \n",
       "I-negative  0.000000  0.000000  \n",
       "I-neutral   0.000000  0.000000  \n",
       "I-positive  0.000000  0.000000  \n",
       "O           0.000247  0.000123  \n",
       "\n",
       "[7 rows x 1598 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "def process_dataset_final_v5(dataset_type):\n",
    "    # Adjusting the paths dynamically based on dataset type\n",
    "    train_path = f\"Data/{dataset_type}/train\"\n",
    "    dev_in_path = f\"Data/{dataset_type}/dev.in\"\n",
    "    dev_out_path = f\"Data/{dataset_type}/dev.out\"\n",
    "    \n",
    "    train_data = load_data_modified_v7(train_path)\n",
    "    dev_in_data = load_dev_in_data(dev_in_path)\n",
    "    with open(dev_out_path, 'r', encoding='utf-8') as f:\n",
    "        dev_tags_actual = [sentence.split() for sentence in f.read().strip().split('\\n\\n')]\n",
    "    \n",
    "    states = {}\n",
    "    observations = {}\n",
    "\n",
    "    for sentence in train_data:\n",
    "        for line in sentence:\n",
    "            match = re.search(r'^(.*)\\s(\\S+)$', line.strip())\n",
    "            if match:\n",
    "                word, tag = match.groups()\n",
    "                states[tag] = states.get(tag, 0) + 1\n",
    "                if tag not in observations:\n",
    "                    observations[tag] = {}\n",
    "                observations[tag][word] = observations[tag].get(word, 0) + 1\n",
    "\n",
    "    state_list = list(states.keys())\n",
    "    start_transition_prob, transition_prob, emission_prob = compute_probabilities_v2(train_data, state_list)\n",
    "\n",
    "    return (start_transition_prob, transition_prob)\n",
    "\n",
    "es_tuple = process_dataset_final_v5(\"ES\")\n",
    "sr_start_probabilities_es = es_tuple[0]\n",
    "df_transition_es = es_tuple[1]\n",
    "\n",
    "ru_tuple = process_dataset_final_v5(\"RU\")\n",
    "sr_start_probabilities_ru = ru_tuple[0]\n",
    "df_transition_ru = ru_tuple[1]\n",
    "\n",
    "sr_start_probabilities_es = pd.Series(sr_start_probabilities_es)\n",
    "df_transition_es = pd.DataFrame(df_transition_es).T\n",
    "df_emission_es = pd.read_csv('Data/ES/csv_dev_in_es_test_e_x_y.csv')\n",
    "df_emission_es = df_emission_es.drop_duplicates(subset=['x','y'], keep='last')\n",
    "df_emission_es = df_emission_es.pivot(index='y', columns='x', values='e(x|y)').fillna(0)\n",
    "display(df_emission_es)\n",
    "\n",
    "sr_start_probabilities_ru = pd.Series(sr_start_probabilities_ru)\n",
    "df_transition_ru = pd.DataFrame(df_transition_ru).T\n",
    "df_emission_ru = pd.read_csv('Data/RU/csv_dev_in_ru_test_e_x_y.csv')\n",
    "df_emission_ru = df_emission_ru.drop_duplicates(subset=['x','y'], keep='last')\n",
    "df_emission_ru = df_emission_ru.pivot(index='y', columns='x', values='e(x|y)').fillna(0)\n",
    "display(df_emission_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(observation, transition, emission, start_probabilities):\n",
    "\n",
    "    states = transition.index.tolist()\n",
    "    state_count = transition.shape[0]\n",
    "    step_count = len(observation)\n",
    "    \n",
    "    # memoizing the incoming edges for each node in the viterbi trellis diagram\n",
    "    df_incoming = np.zeros((state_count , step_count), dtype=int)\n",
    "    df_incoming = pd.DataFrame(df_incoming, index = states)\n",
    "\n",
    "    # memoizing the overall probabilities of arriving at each state at a particular step\n",
    "    # START probabilities\n",
    "    try:\n",
    "        step_probabilities = emission[observation[0]] * start_probabilities\n",
    "    except:\n",
    "        step_probabilities = emission[\"#UNK#\"] * start_probabilities\n",
    "    step_probabilities_temp = pd.Series({state: 0 for state in states})\n",
    "\n",
    "    for step in range(1, step_count):     \n",
    "        for current_state in states:\n",
    "            choosing_max = pd.Series({state: 0 for state in states})\n",
    "            for previous_state in states:\n",
    "                try:\n",
    "                    choosing_max.loc[previous_state] = step_probabilities.loc[previous_state] * transition.loc[previous_state, current_state] * emission.loc[current_state, observation[step]]\n",
    "                except:\n",
    "                    choosing_max.loc[previous_state] = step_probabilities.loc[previous_state] * transition.loc[previous_state, current_state] * emission.loc[current_state, \"#UNK#\"]\n",
    "            max_state = choosing_max.idxmax()\n",
    "            step_probabilities_temp.loc[current_state] = choosing_max.loc[max_state]\n",
    "            df_incoming.loc[current_state, step] = max_state\n",
    "        step_probabilities = step_probabilities_temp.copy()\n",
    "\n",
    "    # get sequences in descending order of likelihood\n",
    "    descending_final_probability_states = step_probabilities.sort_values(ascending=False).index.to_numpy()\n",
    "    df_sequences = np.zeros((state_count , step_count), dtype=int)\n",
    "    df_sequences = pd.DataFrame(df_sequences)\n",
    "    for sequence_rank in range(state_count):\n",
    "        df_sequences.loc[sequence_rank, step_count-1] = descending_final_probability_states[sequence_rank]\n",
    "    for sequence_rank in range(state_count):\n",
    "        for step in range(step_count-2, -1, -1):\n",
    "            previous_state = df_sequences.loc[sequence_rank, step+1]\n",
    "            df_sequences.loc[sequence_rank, step] = df_incoming.loc[previous_state, step+1]\n",
    "\n",
    "    return df_sequences.loc[0].values\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.read().strip().split('\\n\\n')\n",
    "    return [sentence.split('\\n') for sentence in data]\n",
    "\n",
    "es_observations = load_data('Data/ES/dev.in')\n",
    "\n",
    "predicted_tags_viterbi_ES1 = [viterbi([word.split()[0] for word in sentence], df_transition_es, df_emission_es, sr_start_probabilities_es) for sentence in es_observations]\n",
    "\n",
    "predicted_ES1 = []\n",
    "for s in range(len(predicted_tags_viterbi_ES1)):\n",
    "    for i in range(len(predicted_tags_viterbi_ES1[s])):\n",
    "        predicted_ES1.append(es_observations[s][i] + \" \"+ predicted_tags_viterbi_ES1[s][i])\n",
    "    predicted_ES1.append('\\n')\n",
    "\n",
    "with open('Data/ES/dev.p2.out', 'w', encoding='utf-8') as file:\n",
    "    # Write each modified line back to the output file\n",
    "    for line in predicted_ES1:\n",
    "        if line != \"\\n\":\n",
    "            file.write(line + '\\n')\n",
    "        else:\n",
    "            file.write(line)\n",
    "\n",
    "            es_observations = load_data('Data/ES/dev.in')\n",
    "\n",
    "ru_observations = load_data('Data/RU/dev.in')\n",
    "\n",
    "predicted_tags_viterbi_RU1 = [viterbi([word.split()[0] for word in sentence], df_transition_ru, df_emission_ru, sr_start_probabilities_ru) for sentence in ru_observations]\n",
    "\n",
    "predicted_RU1 = []\n",
    "for s in range(len(predicted_tags_viterbi_RU1)):\n",
    "    for i in range(len(predicted_tags_viterbi_RU1[s])):\n",
    "        predicted_RU1.append(ru_observations[s][i] + \" \"+ predicted_tags_viterbi_RU1[s][i])\n",
    "    predicted_RU1.append('\\n')\n",
    "\n",
    "with open('Data/RU/dev.p2.out', 'w', encoding='utf-8') as file:\n",
    "    # Write each modified line back to the output file\n",
    "    for line in predicted_RU1:\n",
    "        if line != \"\\n\":\n",
    "            file.write(line + '\\n')\n",
    "        else:\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_viterbi(observation, transition, emission, start_probabilities, kth_best):\n",
    "    k_best = math.ceil(kth_best/3)\n",
    "    states = transition.index.tolist()\n",
    "    step_count = len(observation)\n",
    "\n",
    "    preceding = {}\n",
    "\n",
    "    preceding = {state: [(0, [])] * k_best for state in states}\n",
    "\n",
    "    for state, sequences in preceding.items():\n",
    "        \n",
    "        try:\n",
    "            preceding[state][0] = (emission[observation[0]][state] * start_probabilities[state], [state])\n",
    "        except:\n",
    "            preceding[state][0] = (emission[\"#UNK#\"][state] * start_probabilities[state], [state])\n",
    "\n",
    "    for step in range(1, step_count):\n",
    "\n",
    "        # refresh current at the beginning of each step\n",
    "        current = {state: [(0, [])] * k_best for state in states}\n",
    "\n",
    "        for current_state in states:\n",
    "\n",
    "            for previous_state in states:\n",
    "\n",
    "                for sequence in preceding[previous_state]:\n",
    "\n",
    "                    # getting the transition probability from preceding state to current state from one of the tuples in the \"preceding\" table\n",
    "                    prev_probability = sequence[0]\n",
    "\n",
    "                    try:\n",
    "                        emission_param = emission.loc[current_state, observation[step]]\n",
    "                    except:\n",
    "                        emission_param = emission.loc[current_state, \"#UNK#\"]\n",
    "                    prev_to_cur_probability = prev_probability * transition.loc[previous_state, current_state] * emission_param\n",
    "\n",
    "                    # sort the tuples in ascending order so that the first tuple has lowest probability\n",
    "                    current[current_state] = sorted(current[current_state], key=lambda x: x[0])\n",
    "                    \n",
    "                    if prev_to_cur_probability >= current[current_state][0][0]:\n",
    "                        sequence_list = copy.deepcopy(sequence[1])\n",
    "                        sequence_list.append(current_state)\n",
    "                        current[current_state][0] = (prev_to_cur_probability, sequence_list)\n",
    "        \n",
    "        # we are either entering the next step or leaving the loop, so preceding becomes current\n",
    "        preceding = copy.deepcopy(current)\n",
    "\n",
    "    combined_list = []\n",
    "    for sequences in preceding.values():\n",
    "        combined_list.extend(sequences)\n",
    "\n",
    "    combined_list = sorted(combined_list, key=lambda x: x[0])[::-1]\n",
    "\n",
    "    return combined_list[kth_best-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.read().strip().split('\\n\\n')\n",
    "    return [sentence.split('\\n') for sentence in data]\n",
    "\n",
    "es_observations = load_data('Data/ES/dev.in')\n",
    "ru_observations = load_data('Data/RU/dev.in')\n",
    "\n",
    "predicted_tags_viterbi_ES2 = [modified_viterbi([word.split()[0] for word in sentence], df_transition_es, df_emission_es, sr_start_probabilities_es, 2)[1] for sentence in es_observations]\n",
    "predicted_tags_viterbi_ES8 = [modified_viterbi([word.split()[0] for word in sentence], df_transition_es, df_emission_es, sr_start_probabilities_es, 8)[1] for sentence in es_observations]\n",
    "predicted_tags_viterbi_RU2 = [modified_viterbi([word.split()[0] for word in sentence], df_transition_ru, df_emission_ru, sr_start_probabilities_ru, 2)[1] for sentence in ru_observations]\n",
    "predicted_tags_viterbi_RU8 = [modified_viterbi([word.split()[0] for word in sentence], df_transition_ru, df_emission_ru, sr_start_probabilities_ru, 8)[1] for sentence in ru_observations]\n",
    "\n",
    "predicted_ES2 = []\n",
    "for s in range(len(predicted_tags_viterbi_ES2)):\n",
    "    for i in range(len(predicted_tags_viterbi_ES2[s])):\n",
    "        predicted_ES2.append(es_observations[s][i] + \" \"+ predicted_tags_viterbi_ES2[s][i])\n",
    "    predicted_ES2.append('\\n')\n",
    "\n",
    "predicted_ES8 = []\n",
    "for s in range(len(predicted_tags_viterbi_ES8)):\n",
    "    for i in range(len(predicted_tags_viterbi_ES8[s])):\n",
    "        predicted_ES8.append(es_observations[s][i] + \" \"+ predicted_tags_viterbi_ES8[s][i])\n",
    "    predicted_ES8.append('\\n')\n",
    "\n",
    "predicted_RU2 = []\n",
    "for s in range(len(predicted_tags_viterbi_RU2)):\n",
    "    for i in range(len(predicted_tags_viterbi_RU2[s])):\n",
    "        predicted_RU2.append(ru_observations[s][i] + \" \"+ predicted_tags_viterbi_RU2[s][i])\n",
    "    predicted_RU2.append('\\n')\n",
    "\n",
    "predicted_RU8 = []\n",
    "for s in range(len(predicted_tags_viterbi_RU8)):\n",
    "    for i in range(len(predicted_tags_viterbi_RU8[s])):\n",
    "        predicted_RU8.append(ru_observations[s][i] + \" \"+ predicted_tags_viterbi_RU8[s][i])\n",
    "    predicted_RU8.append('\\n')\n",
    "\n",
    "with open('Data/ES/dev.p3.2nd.out', 'w', encoding='utf-8') as file:\n",
    "    # Write each modified line back to the output file\n",
    "    for line in predicted_ES2:\n",
    "        if line != \"\\n\":\n",
    "            file.write(line + '\\n')\n",
    "        else:\n",
    "            file.write(line)\n",
    "\n",
    "with open('Data/ES/dev.p3.8th.out', 'w', encoding='utf-8') as file:\n",
    "    # Write each modified line back to the output file\n",
    "    for line in predicted_ES8:\n",
    "        if line != \"\\n\":\n",
    "            file.write(line + '\\n')\n",
    "        else:\n",
    "            file.write(line)\n",
    "\n",
    "with open('Data/RU/dev.p3.2nd.out', 'w', encoding='utf-8') as file:\n",
    "    # Write each modified line back to the output file\n",
    "    for line in predicted_RU2:\n",
    "        if line != \"\\n\":\n",
    "            file.write(line + '\\n')\n",
    "        else:\n",
    "            file.write(line)\n",
    "\n",
    "with open('Data/RU/dev.p3.8th.out', 'w', encoding='utf-8') as file:\n",
    "    # Write each modified line back to the output file\n",
    "    for line in predicted_RU8:\n",
    "        if line != \"\\n\":\n",
    "            file.write(line + '\\n')\n",
    "        else:\n",
    "            file.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
