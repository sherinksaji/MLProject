{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function that estimates the emission parameters from the training set using MLE (maximum likelihoodestimation):\n",
    "Which training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_to_df is a function to convert some data file into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_df (file_path):\n",
    "\n",
    "\n",
    "  with open(file_path, 'r',encoding='utf-8') as file:\n",
    "      lines = file.readlines()\n",
    "      data = [line.strip().split(' ', maxsplit=2)[:2] for line in lines]\n",
    "\n",
    "  # Create the dataframe\n",
    "  df = pd.DataFrame(data, columns=['x', 'y'])\n",
    "  #drop rows where value for y=None\n",
    "  df = df.dropna(subset=['y'])\n",
    "\n",
    "  df['x'] = df['x'].astype(str)\n",
    "  df['y'] = df['y'].astype(str)\n",
    "  # Display the dataframe\n",
    "  #print(\"Here is dataframe created for the file path: \",file_path,\"\\n\")\n",
    "  #print(df.to_string)\n",
    "  return df\n",
    "\n",
    "file_path_train_es='Data/ES/train'\n",
    "df_train_es=file_to_df(file_path_train_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_y(df,y_value):\n",
    "    unique_counts = df['y'].value_counts().to_dict()\n",
    "    print(\"unique counts:\",unique_counts)\n",
    "    return unique_counts[y_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_star_with_smallest_count(df):\n",
    "     unique_counts = df['y_star'].value_counts().to_dict()\n",
    "     min_count = min(unique_counts.values())\n",
    "     y_with_min_count = [key for key, value in unique_counts.items() if value == min_count]         \n",
    "     return y_with_min_count[0]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_of_y_with_smallest_count(df):\n",
    "     unique_counts = df['y'].value_counts().to_dict()\n",
    "     min_count = min(unique_counts.values())\n",
    "     y_with_min_count = [key for key, value in unique_counts.items() if value == min_count]         \n",
    "     return min_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_filtered_for_y_value(df,y_value):\n",
    "  return df[df['y'] == y_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_x_count_y_to_x(df):\n",
    "    df_x_count_y_to_x = df['x'].value_counts().reset_index()\n",
    "\n",
    "    df_x_count_y_to_x.columns = ['x', 'count_y_to_x']\n",
    "\n",
    "    return df_x_count_y_to_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-positive' 'B-negative' 'B-neutral' 'I-neutral' 'I-positive'\n",
      " 'I-negative']\n"
     ]
    }
   ],
   "source": [
    "def create_ls_of_all_y_values(df):\n",
    "    unique_values = df['y'].unique()\n",
    "    return (unique_values)\n",
    "print(create_ls_of_all_y_values(df_train_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "               x  count_y_to_x    e(x|y)           y\n",
      "0         comida           169  0.145690  B-positive\n",
      "1       servicio           122  0.105172  B-positive\n",
      "2    restaurante            46  0.039655  B-positive\n",
      "3          trato            44  0.037931  B-positive\n",
      "4       ambiente            33  0.028448  B-positive\n",
      "..           ...           ...       ...         ...\n",
      "280       dorada             1  0.000862  B-positive\n",
      "281      detalle             1  0.000862  B-positive\n",
      "282   cantidades             1  0.000862  B-positive\n",
      "283       Atteca             1  0.000862  B-positive\n",
      "284        menus             1  0.000862  B-positive\n",
      "\n",
      "[285 rows x 4 columns]\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "def create_df_e_x_y_train(train_df,y_value):\n",
    "   \n",
    "    df_train_filtered_for_y = create_df_filtered_for_y_value(train_df,y_value)\n",
    "    df_e_x_y_train=create_df_x_count_y_to_x(df_train_filtered_for_y)\n",
    "    df_e_x_y_train['e(x|y)'] = df_e_x_y_train['count_y_to_x']/(count_y(train_df,y_value))\n",
    "    df_e_x_y_train['y']=y_value\n",
    "    return df_e_x_y_train\n",
    "\n",
    "\n",
    "df_e_x_y_train_for_I_neutral=create_df_e_x_y_train(df_train_es,\"B-positive\")\n",
    "print(df_e_x_y_train_for_I_neutral)\n",
    "print(df_e_x_y_train_for_I_neutral['e(x|y)'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n",
      "0.9937888198757765\n",
      "               x  count_y_to_x    e(x|y)\n",
      "0       servicio            24  0.149068\n",
      "1         comida            23  0.142857\n",
      "2    restaurante             8  0.049689\n",
      "3       ambiente             7  0.043478\n",
      "4         platos             6  0.037267\n",
      "..           ...           ...       ...\n",
      "67      cocinero             1  0.006211\n",
      "68        tartar             1  0.006211\n",
      "69       postres             1  0.006211\n",
      "70  localizaciÃ³n             1  0.006211\n",
      "71         comer             1  0.006211\n",
      "\n",
      "[72 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_df_e_x_y_test(test_df,y_value,train_df):\n",
    "    k=1\n",
    "    #print(test_df.info())\n",
    "    df_test_filtered_for_y = create_df_filtered_for_y_value(test_df,y_value)\n",
    "    #print(df_test_filtered_for_y)\n",
    "    df_e_x_y_test=create_df_x_count_y_to_x(df_test_filtered_for_y)\n",
    "    #print (df_e_x_y_test)\n",
    "    \n",
    "    count_y_plus_k=count_y(test_df,y_value)+k\n",
    "\n",
    "    #make a list of all the x values in the train_df's x column\n",
    "   \n",
    "\n",
    "    \n",
    "    train_df_x_values = train_df['x'].tolist()\n",
    "    #print(train_df_x_values)\n",
    "    \n",
    "    df_e_x_y_test['x'] = df_e_x_y_test['x'].apply(lambda x: x if x in train_df_x_values else \"#UNK#\") #if word does or does not appear in training set\n",
    "    #print(df_e_x_y_test)\n",
    "    \n",
    "    df_e_x_y_test['e(x|y)'] = df_e_x_y_test.apply(lambda row: (row['count_y_to_x'] / count_y_plus_k) if row['x'] != '#UNK#' else (k / count_y_plus_k), axis=1)\n",
    "    print(df_e_x_y_test['e(x|y)'].sum())\n",
    "\n",
    "    #case 1\n",
    "    #df_e_x_y_test['e(x|y)'] = df_e_x_y_test['count_y_to_x']/count_y_plus_k\n",
    "\n",
    "    #case 2\n",
    "    #df_e_x_y_test['e(x|y)'] = k/count_y_plus_k\n",
    "\n",
    "\n",
    "    return df_e_x_y_test\n",
    "\n",
    "\n",
    "file_path_test_es='Data/ES/dev.out'\n",
    "df_test_es=file_to_df(file_path_test_es)\n",
    "df_e_x_y_test_for_I_neutral=create_df_e_x_y_test(df_test_es,\"B-positive\",df_train_es)\n",
    "print(df_e_x_y_test_for_I_neutral)\n",
    "# count_unk = 0\n",
    "# value_counts = df_e_x_y_test_for_I_neutral['x'].value_counts()\n",
    "# print(value_counts)\n",
    "# if '#UNK#' in value_counts.index:\n",
    "#     count_unk = value_counts['#UNK#']\n",
    "# print(count_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_e_x_y_df_generated_labels(test_df,y_value,train_df): # same as create_df_e_x_y_test but we fix count_y_plus_k to give the e(x|y) for y star\n",
    "    k=1\n",
    "    #print(test_df.info())\n",
    "    df_test_filtered_for_y = create_df_filtered_for_y_value(test_df,y_value)\n",
    "    #print(df_test_filtered_for_y)\n",
    "    df_e_x_y_test=create_df_x_count_y_to_x(df_test_filtered_for_y)\n",
    "    #print (df_e_x_y_test)\n",
    "    \n",
    "    count_y_plus_k=count_of_y_with_smallest_count(train_df) +k\n",
    "\n",
    "    #make a list of all the x values in the train_df's x column\n",
    "   \n",
    "\n",
    "    \n",
    "    train_df_x_values = train_df['x'].tolist()\n",
    "    #print(train_df_x_values)\n",
    "    \n",
    "    df_e_x_y_test['x'] = df_e_x_y_test['x'].apply(lambda x: x if x in train_df_x_values else \"#UNK#\") #if word does or does not appear in training set\n",
    "    #print(df_e_x_y_test)\n",
    "    \n",
    "    df_e_x_y_test['e(x|y)'] = df_e_x_y_test.apply(lambda row: (row['count_y_to_x'] / count_y_plus_k) if row['x'] != '#UNK#' else (k / count_y_plus_k), axis=1)\n",
    "    print(df_e_x_y_test['e(x|y)'].sum())\n",
    "\n",
    "    #case 1\n",
    "    #df_e_x_y_test['e(x|y)'] = df_e_x_y_test['count_y_to_x']/count_y_plus_k\n",
    "\n",
    "    #case 2\n",
    "    #df_e_x_y_test['e(x|y)'] = k/count_y_plus_k\n",
    "\n",
    "\n",
    "    return df_e_x_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_e_x_y_df_train_all_y_values(file_path):\n",
    "    \n",
    "  df_train=file_to_df(file_path)\n",
    "  #print(df_train_es)\n",
    "  ls_df_train=[]\n",
    "  ls_y_values=create_ls_of_all_y_values(df_train)\n",
    "  #print(len(ls_y_values))\n",
    "  for y_value in ls_y_values:\n",
    "    if y_value!=None:\n",
    "      df_e_x_y=create_df_e_x_y_train(df_train,y_value)\n",
    "      ls_df_train.append(df_e_x_y)\n",
    "  #print(len(ls_df_train))\n",
    "  \n",
    "  combined_df_train=pd.concat(ls_df_train,axis=0)\n",
    "  return (combined_df_train)\n",
    "#file_path_train_es='Data/ES/train'\n",
    "#print(create_e_x_y_df_train_all_y_values(file_path_train_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937888198757765\n",
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n",
      "0.9800000000000002\n",
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n",
      "0.9967491872968243\n",
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n",
      "0.9838709677419354\n",
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n",
      "0.972972972972973\n",
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n",
      "0.8888888888888891\n"
     ]
    }
   ],
   "source": [
    "def create_e_x_y_df_test_all_y_values(file_path_train,file_path_test):\n",
    "    \n",
    "  df_train=file_to_df(file_path_train)\n",
    "  df_test=file_to_df(file_path_test)\n",
    "  #print(df_train_es)\n",
    "  ls_df_test=[]\n",
    "  ls_y_values=create_ls_of_all_y_values(df_test)\n",
    "  #print(len(ls_y_values))\n",
    "  for y_value in ls_y_values:\n",
    "    if y_value!=None:\n",
    "      df_e_x_y=create_df_e_x_y_test(df_test,y_value,df_train)\n",
    "      ls_df_test.append(df_e_x_y)\n",
    "  #print(len(ls_df_train))\n",
    "  \n",
    "  combined_df_test=pd.concat(ls_df_test,axis=0)\n",
    "  return (combined_df_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path_dev_out_es='Data/ES/dev.out'\n",
    "file_path_train_es='Data/ES/train'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_dev_out_es_test_e_x_y=create_e_x_y_df_test_all_y_values(file_path_train_es,file_path_dev_out_es)\n",
    "csv_dev_out_es_test_e_x_y=df_dev_out_es_test_e_x_y.to_csv('csv_dev_out_es_test_e_x_y.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n"
     ]
    }
   ],
   "source": [
    "def create_df_x_to_y_star(file_path):\n",
    "    e_x_y_df_train=create_e_x_y_df_train_all_y_values(file_path)\n",
    "    \n",
    "    # Group by 'x' and find the maximum 'e(x|y)' value for each group\n",
    "    df_x_to_y_star = e_x_y_df_train.groupby('x')['e(x|y)'].max().reset_index()\n",
    "\n",
    "    # Find the corresponding 'y' values for the maximum 'e(x|y)' values\n",
    "    df_x_to_y_star = pd.merge(df_x_to_y_star, e_x_y_df_train, on=['x', 'e(x|y)'])\n",
    "\n",
    "    # Rename the columns\n",
    "    df_x_to_y_star.columns = ['x', 'max_e(x|y)','count_y_to_x', 'y_star']\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    return (df_x_to_y_star)\n",
    "    \n",
    "file_path_train_es='Data/ES/train'    \n",
    "df_x_to_y_star=create_df_x_to_y_star(file_path_train_es)\n",
    "csv_x_to_y_star = df_x_to_y_star.to_csv('train_x_to_y_star.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n"
     ]
    }
   ],
   "source": [
    "def generate_y_values(file_path_dev_in,file_path_train,file_path_dev_p1_out):\n",
    "    df_train=create_df_x_to_y_star(file_path_train)\n",
    "    x_values=df_train['x'].tolist()\n",
    "    #the y_label that has the smallest count_y will generate the biggest k / count_y_plus_k which will give the maximum e(x|y) which means that y_label is y_star\n",
    "    #so that y_label is:\n",
    "    y_label=y_star_with_smallest_count(df_train) \n",
    "    with open(file_path_dev_in, 'r',encoding='utf-8') as file:\n",
    "      lines = file.readlines()\n",
    "      for l in range(len(lines)):\n",
    "        line=lines[l].strip()\n",
    "        if line in x_values:\n",
    "          possible_y_values=df_train[df_train['x'] == line]['y_star'].tolist()\n",
    "          lines[l]=line+\" \"+possible_y_values[0]\n",
    "         \n",
    "          if (len(possible_y_values)!=1):\n",
    "            print (\"something wrong: x_vlaues in df_train not unique for some reason,for line: \",l)\n",
    "        else:\n",
    "          if (line!=\"\"):\n",
    "             line=line+\" \"+y_label\n",
    "             lines[l]=line\n",
    "          else:\n",
    "            lines[l]=\"\"\n",
    "          \n",
    "    with open(file_path_dev_p1_out, 'w',encoding='utf-8') as file:\n",
    "        \n",
    "        for line in lines:\n",
    "          file.write(line+\"\\n\")   \n",
    "         \n",
    "         \n",
    "\n",
    "   \n",
    "file_path_dev_in_es = 'Data/ES/dev.in'   \n",
    "file_path_train_es='Data/ES/train'  \n",
    "file_path_dev_p1_out_es='Data/ES/dev.p1.out' \n",
    "generate_y_values(file_path_dev_in_es,file_path_train_es,file_path_dev_p1_out_es)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 28\u001b[0m\n\u001b[0;32m     21\u001b[0m file_path_dev_p1_out_es\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mData/ES/dev.p1.out\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     22\u001b[0m file_path_train_es\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mData/ES/train\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 28\u001b[0m df_dev_p1_out_es_test_e_x_y\u001b[39m=\u001b[39mcreate_e_x_y_df_generated_all_y_values(file_path_train_es,file_path_dev_p1_out_es)\n\u001b[0;32m     29\u001b[0m csv_dev_p1_out_es_test_e_x_y\u001b[39m=\u001b[39mdf_dev_p1_out_es_test_e_x_y\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mcsv_dev_p1_out_es_e_x_y.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[86], line 11\u001b[0m, in \u001b[0;36mcreate_e_x_y_df_generated_all_y_values\u001b[1;34m(file_path_train, file_path_test)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m y_value \u001b[39min\u001b[39;00m ls_y_values:\n\u001b[0;32m     10\u001b[0m   \u001b[39mif\u001b[39;00m y_value\u001b[39m!=\u001b[39m\u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     df_e_x_y\u001b[39m=\u001b[39mcreate_e_x_y_df_generated_labels(df_test,y_value,df_train)\n\u001b[0;32m     12\u001b[0m     ls_df_test\u001b[39m.\u001b[39mappend(df_e_x_y)\n\u001b[0;32m     13\u001b[0m \u001b[39m#print(len(ls_df_train))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[81], line 9\u001b[0m, in \u001b[0;36mcreate_e_x_y_df_generated_labels\u001b[1;34m(test_df, y_value, train_df)\u001b[0m\n\u001b[0;32m      6\u001b[0m df_e_x_y_test\u001b[39m=\u001b[39mcreate_df_x_count_y_to_x(df_test_filtered_for_y)\n\u001b[0;32m      7\u001b[0m \u001b[39m#print (df_e_x_y_test)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m count_y_plus_k\u001b[39m=\u001b[39my_with_smallest_count(train_df) \u001b[39m+\u001b[39;49mk\n\u001b[0;32m     11\u001b[0m \u001b[39m#make a list of all the x values in the train_df's x column\u001b[39;00m\n\u001b[0;32m     15\u001b[0m train_df_x_values \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "def create_e_x_y_df_generated_all_y_values(file_path_train,file_path_test):\n",
    "    \n",
    "  df_train=file_to_df(file_path_train)\n",
    "  df_test=file_to_df(file_path_test)\n",
    "  #print(df_train_es)\n",
    "  ls_df_test=[]\n",
    "  ls_y_values=create_ls_of_all_y_values(df_test)\n",
    "  #print(len(ls_y_values))\n",
    "  for y_value in ls_y_values:\n",
    "    if y_value!=None:\n",
    "      df_e_x_y=create_e_x_y_df_generated_labels(df_test,y_value,df_train)\n",
    "      ls_df_test.append(df_e_x_y)\n",
    "  #print(len(ls_df_train))\n",
    "  \n",
    "  combined_df_test=pd.concat(ls_df_test,axis=0)\n",
    "  return (combined_df_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path_dev_p1_out_es='Data/ES/dev.p1.out'\n",
    "file_path_train_es='Data/ES/train'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_dev_p1_out_es_test_e_x_y=create_e_x_y_df_generated_all_y_values(file_path_train_es,file_path_dev_p1_out_es)\n",
    "csv_dev_p1_out_es_test_e_x_y=df_dev_p1_out_es_test_e_x_y.to_csv('csv_dev_p1_out_es_e_x_y.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
