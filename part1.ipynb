{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function that estimates the emission parameters from the training set using MLE (maximum likelihoodestimation):\n",
    "Which training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_to_df is a function to convert some data file into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_df (file_path):\n",
    "\n",
    "\n",
    "  with open(file_path, 'r',encoding='utf-8') as file:\n",
    "      lines = file.readlines()\n",
    "      data = [line.strip().split(' ', maxsplit=2)[:2] for line in lines]\n",
    "\n",
    "  # Create the dataframe\n",
    "  df = pd.DataFrame(data, columns=['x', 'y'])\n",
    "  #drop rows where value for y=None\n",
    "  df = df.dropna(subset=['y'])\n",
    "\n",
    "  df['x'] = df['x'].astype(str)\n",
    "  df['y'] = df['y'].astype(str)\n",
    "  # Display the dataframe\n",
    "  #print(\"Here is dataframe created for the file path: \",file_path,\"\\n\")\n",
    "  #print(df.to_string)\n",
    "  return df\n",
    "\n",
    "file_path_train_es='Data/ES/train'\n",
    "df_train_es=file_to_df(file_path_train_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_y(df,y_value):\n",
    "    unique_counts = df['y'].value_counts().to_dict()\n",
    "    print(\"unique counts:\",unique_counts)\n",
    "    return unique_counts[y_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_star_with_smallest_count(df):\n",
    "     unique_counts = df['y_star'].value_counts().to_dict()\n",
    "     min_count = min(unique_counts.values())\n",
    "     y_with_min_count = [key for key, value in unique_counts.items() if value == min_count]         \n",
    "     return y_with_min_count[0]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_filtered_for_y_value(df,y_value):\n",
    "  return df[df['y'] == y_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_x_count_y_to_x(df):\n",
    "    df_x_count_y_to_x = df['x'].value_counts().reset_index()\n",
    "\n",
    "    df_x_count_y_to_x.columns = ['x', 'count_y_to_x']\n",
    "\n",
    "    return df_x_count_y_to_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-positive' 'B-negative' 'B-neutral' 'I-neutral' 'I-positive'\n",
      " 'I-negative']\n"
     ]
    }
   ],
   "source": [
    "def create_ls_of_all_y_values(df):\n",
    "    unique_values = df['y'].unique()\n",
    "    return (unique_values)\n",
    "print(create_ls_of_all_y_values(df_train_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "               x  count_y_to_x    e(x|y)           y\n",
      "0         comida           169  0.145690  B-positive\n",
      "1       servicio           122  0.105172  B-positive\n",
      "2    restaurante            46  0.039655  B-positive\n",
      "3          trato            44  0.037931  B-positive\n",
      "4       ambiente            33  0.028448  B-positive\n",
      "..           ...           ...       ...         ...\n",
      "280       dorada             1  0.000862  B-positive\n",
      "281      detalle             1  0.000862  B-positive\n",
      "282   cantidades             1  0.000862  B-positive\n",
      "283       Atteca             1  0.000862  B-positive\n",
      "284        menus             1  0.000862  B-positive\n",
      "\n",
      "[285 rows x 4 columns]\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "def create_df_e_x_y_train(train_df,y_value):\n",
    "   \n",
    "    df_train_filtered_for_y = create_df_filtered_for_y_value(train_df,y_value)\n",
    "    df_e_x_y_train=create_df_x_count_y_to_x(df_train_filtered_for_y)\n",
    "    df_e_x_y_train['e(x|y)'] = df_e_x_y_train['count_y_to_x']/(count_y(train_df,y_value))\n",
    "    df_e_x_y_train['y']=y_value\n",
    "    return df_e_x_y_train\n",
    "\n",
    "\n",
    "df_e_x_y_train_for_I_neutral=create_df_e_x_y_train(df_train_es,\"B-positive\")\n",
    "print(df_e_x_y_train_for_I_neutral)\n",
    "print(df_e_x_y_train_for_I_neutral['e(x|y)'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 3998, 'B-positive': 160, 'B-negative': 61, 'I-positive': 49, 'I-negative': 36, 'B-neutral': 8}\n",
      "0.9937888198757765\n",
      "               x  count_y_to_x    e(x|y)\n",
      "0       servicio            24  0.149068\n",
      "1         comida            23  0.142857\n",
      "2    restaurante             8  0.049689\n",
      "3       ambiente             7  0.043478\n",
      "4         platos             6  0.037267\n",
      "..           ...           ...       ...\n",
      "67      cocinero             1  0.006211\n",
      "68        tartar             1  0.006211\n",
      "69       postres             1  0.006211\n",
      "70  localizaci√≥n             1  0.006211\n",
      "71         comer             1  0.006211\n",
      "\n",
      "[72 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_df_e_x_y_test(test_df,y_value,train_df):\n",
    "    k=1\n",
    "    #print(test_df.info())\n",
    "    df_test_filtered_for_y = create_df_filtered_for_y_value(test_df,y_value)\n",
    "    #print(df_test_filtered_for_y)\n",
    "    df_e_x_y_test=create_df_x_count_y_to_x(df_test_filtered_for_y)\n",
    "    #print (df_e_x_y_test)\n",
    "    \n",
    "    count_y_plus_k=count_y(test_df,y_value)+k\n",
    "\n",
    "    #make a list of all the x values in the train_df's x column\n",
    "   \n",
    "\n",
    "    \n",
    "    train_df_x_values = train_df['x'].tolist()\n",
    "    #print(train_df_x_values)\n",
    "    \n",
    "    df_e_x_y_test['x'] = df_e_x_y_test['x'].apply(lambda x: x if x in train_df_x_values else \"#UNK#\") #if word does or does not appear in training set\n",
    "    #print(df_e_x_y_test)\n",
    "    \n",
    "    df_e_x_y_test['e(x|y)'] = df_e_x_y_test.apply(lambda row: (row['count_y_to_x'] / count_y_plus_k) if row['x'] != '#UNK#' else (k / count_y_plus_k), axis=1)\n",
    "    print(df_e_x_y_test['e(x|y)'].sum())\n",
    "\n",
    "    #case 1\n",
    "    #df_e_x_y_test['e(x|y)'] = df_e_x_y_test['count_y_to_x']/count_y_plus_k\n",
    "\n",
    "    #case 2\n",
    "    #df_e_x_y_test['e(x|y)'] = k/count_y_plus_k\n",
    "\n",
    "\n",
    "    return df_e_x_y_test\n",
    "\n",
    "\n",
    "file_path_test_es='Data/ES/dev.out'\n",
    "df_test_es=file_to_df(file_path_test_es)\n",
    "df_e_x_y_test_for_I_neutral=create_df_e_x_y_test(df_test_es,\"B-positive\",df_train_es)\n",
    "print(df_e_x_y_test_for_I_neutral)\n",
    "# count_unk = 0\n",
    "# value_counts = df_e_x_y_test_for_I_neutral['x'].value_counts()\n",
    "# print(value_counts)\n",
    "# if '#UNK#' in value_counts.index:\n",
    "#     count_unk = value_counts['#UNK#']\n",
    "# print(count_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_e_x_y_df_train_all_y_values(file_path):\n",
    "    \n",
    "  df_train=file_to_df(file_path)\n",
    "  #print(df_train_es)\n",
    "  ls_df_train=[]\n",
    "  ls_y_values=create_ls_of_all_y_values(df_train)\n",
    "  #print(len(ls_y_values))\n",
    "  for y_value in ls_y_values:\n",
    "    if y_value!=None:\n",
    "      df_e_x_y=create_df_e_x_y_train(df_train,y_value)\n",
    "      ls_df_train.append(df_e_x_y)\n",
    "  #print(len(ls_df_train))\n",
    "  \n",
    "  combined_df_train=pd.concat(ls_df_train,axis=0)\n",
    "  return (combined_df_train)\n",
    "#file_path_train_es='Data/ES/train'\n",
    "#print(create_e_x_y_df_train_all_y_values(file_path_train_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n"
     ]
    }
   ],
   "source": [
    "def create_df_x_to_y_star(file_path):\n",
    "    e_x_y_df_train=create_e_x_y_df_train_all_y_values(file_path)\n",
    "    \n",
    "    # Group by 'x' and find the maximum 'e(x|y)' value for each group\n",
    "    df_x_to_y_star = e_x_y_df_train.groupby('x')['e(x|y)'].max().reset_index()\n",
    "\n",
    "    # Find the corresponding 'y' values for the maximum 'e(x|y)' values\n",
    "    df_x_to_y_star = pd.merge(df_x_to_y_star, e_x_y_df_train, on=['x', 'e(x|y)'])\n",
    "\n",
    "    # Rename the columns\n",
    "    df_x_to_y_star.columns = ['x', 'max_e(x|y)','count_y_to_x', 'y_star']\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    return (df_x_to_y_star)\n",
    "    \n",
    "file_path_train_es='Data/ES/train'    \n",
    "df_x_to_y_star=create_df_x_to_y_star(file_path_train_es)\n",
    "csv_x_to_y_star = df_x_to_y_star.to_csv('train_x_to_y_star.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n",
      "unique counts: {'O': 29035, 'B-positive': 1160, 'B-negative': 381, 'I-positive': 314, 'I-negative': 171, 'B-neutral': 72, 'I-neutral': 43}\n"
     ]
    }
   ],
   "source": [
    "def generate_y_values(file_path_dev_in,file_path_train,file_path_dev_p1_out):\n",
    "    df_train=create_df_x_to_y_star(file_path_train)\n",
    "    x_values=df_train['x'].tolist()\n",
    "    #the y_label that has the smallest count_y will generate the biggest k / count_y_plus_k which will give the maximum e(x|y) which means that y_label is y_star\n",
    "    #so that y_label is:\n",
    "    y_label=y_star_with_smallest_count(df_train) \n",
    "    with open(file_path_dev_in, 'r',encoding='utf-8') as file:\n",
    "      lines = file.readlines()\n",
    "      for l in range(len(lines)):\n",
    "        line=lines[l].strip()\n",
    "        if line in x_values:\n",
    "          possible_y_values=df_train[df_train['x'] == line]['y_star'].tolist()\n",
    "          lines[l]=line+\" \"+possible_y_values[0]\n",
    "         \n",
    "          if (len(possible_y_values)!=1):\n",
    "            print (\"something wrong: x_vlaues in df_train not unique for some reason,for line: \",l)\n",
    "        else:\n",
    "          if (line!=\"\"):\n",
    "             line=line+\" \"+y_label\n",
    "             lines[l]=line\n",
    "          else:\n",
    "            lines[l]=\"\"\n",
    "          \n",
    "    with open(file_path_dev_p1_out, 'w',encoding='utf-8') as file:\n",
    "        \n",
    "        for line in lines:\n",
    "          file.write(line+\"\\n\")   \n",
    "         \n",
    "         \n",
    "\n",
    "   \n",
    "file_path_dev_in_es = 'Data/ES/dev.in'   \n",
    "file_path_train_es='Data/ES/train'  \n",
    "file_path_dev_p1_out_es='Data/ES/dev.p1.out' \n",
    "generate_y_values(file_path_dev_in_es,file_path_train_es,file_path_dev_p1_out_es)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4312\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sherin Saji\\AppData\\Local\\Temp\\ipykernel_9528\\2950593151.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  count_same = df1[df1.eq(df2).all(axis=1)].shape[0]\n",
      "C:\\Users\\Sherin Saji\\AppData\\Local\\Temp\\ipykernel_9528\\2950593151.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  count_not_same = df1[df1.ne(df2).any(axis=1)].shape[0]\n",
      "C:\\Users\\Sherin Saji\\AppData\\Local\\Temp\\ipykernel_9528\\2950593151.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  rows_not_same = df1[~df1.eq(df2).all(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "file_path_dev_p1_out_es='Data/ES/dev.p1.out'\n",
    "file_dev_out_es='Data/ES/dev.out'\n",
    "df_dev_p1_out_es= file_to_df (file_path_dev_p1_out_es)\n",
    "df_dev_out_es=file_to_df (file_dev_out_es)\n",
    "print(df_dev_p1_out_es.shape[0])\n",
    "print(df_dev_out_es.shape[0])\n",
    "\n",
    "df1=df_dev_p1_out_es\n",
    "df2=df_dev_out_es\n",
    "\n",
    "# Compare rows\n",
    "comparison = df1.equals(df2)\n",
    "\n",
    "# Get the count of rows that are the same\n",
    "count_same = df1[df1.eq(df2).all(axis=1)].shape[0]\n",
    "\n",
    "# Get the count of rows that are not the same\n",
    "count_not_same = df1[df1.ne(df2).any(axis=1)].shape[0]\n",
    "\n",
    "# Get the rows that are not the same\n",
    "rows_not_same = df1[~df1.eq(df2).all(axis=1)]\n",
    "\n",
    "total_number_of_correctly_predicted_entries=count_same\n",
    "total_number_of_predicted_entities=df1.shape[0]\n",
    "precision=total_number_of_correctly_predicted_entries/total_number_of_predicted_entities\n",
    "print(precision)\n",
    "\n",
    "# Display the results\n",
    "# print(\"Comparison result:\", comparison)\n",
    "# print(\"Count of rows that are the same:\", count_same)\n",
    "# print(\"Count of rows that are not the same:\", count_not_same)\n",
    "# print(\"Rows that are not the same:\\n\", rows_not_same)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
